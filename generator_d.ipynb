{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/ai-creator-archive/blob/main/generator_d.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru4AP9GVFlqQ"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!pip install diffusers==0.14.0 transformers piexif fold_to_ascii discord ftfy omegaconf -U\n",
        "!git clone -b v0.14.0 https://github.com/huggingface/diffusers\n",
        "\n",
        "import os, gc, requests, json, piexif, torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "from fold_to_ascii import fold\n",
        "\n",
        "metadata = PngInfo()\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "root_folder = 'images'\n",
        "\n",
        "if os.path.exists(f\"{root_folder}\") == False:\n",
        "    os.mkdir(f\"{root_folder}\")\n",
        "image_folder = max([int(f) for f in os.listdir(f\"{root_folder}\")], default=0)\n",
        "if os.path.exists(f\"{root_folder}/{image_folder:04}\") == False:\n",
        "    os.mkdir(f\"{root_folder}/{image_folder:04}\")\n",
        "name = max([int(f[: f.index(\".\")]) for f in os.listdir(f\"{root_folder}/{image_folder:04}\")], default=0)\n",
        "\n",
        "def generate(discord_token, discord_channel_id, ckpt, discord_user, by, num_inference_steps, guidance_scale, sampler, width, height, prompt, negative_prompt, suffix, image_folder, name):\n",
        "    model_suffix = ckpt.split(\"/\")[-1].split(\".\")[-1]\n",
        "    !rm /content/model.{model_suffix}\n",
        "    !rm -rf /content/pt\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {ckpt} -d /content -o model.{model_suffix}\n",
        "\n",
        "    if 'pipe' in globals():  \n",
        "      del pipe\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    !python /content/diffusers/scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path /content/model.{model_suffix} --dump_path /content/pt\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"/content/pt\", torch_dtype=torch.float16, safety_checker=None).to(\"cuda\")\n",
        "    \n",
        "    width = closestNumber(width, 8)\n",
        "    height = closestNumber(height, 8)\n",
        "    metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "    metadata.add_text(\"by\", f\"{by}\")\n",
        "    gc.collect()\n",
        "    real_seed = torch.cuda.initial_seed()\n",
        "    image = pipe(prompt=prompt, negative_prompt=negative_prompt, num_inference_steps=num_inference_steps, height=height, width=width, guidance_scale=guidance_scale).images[0]\n",
        "    if(suffix == 'png'):\n",
        "      image.save(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", pnginfo=metadata)\n",
        "    else:\n",
        "      zeroth_ifd = {piexif.ImageIFD.ImageDescription: f\"{fold(prompt)}\", piexif.ImageIFD.Make: f\"{fold(by)}\", piexif.ImageIFD.Model: f\"{ckpt}\", piexif.ImageIFD.Copyright: f\"Attribution 4.0 International (CC BY 4.0)\"}\n",
        "      exif_dict = {\"0th\": zeroth_ifd}\n",
        "      exif_bytes = piexif.dump(exif_dict)\n",
        "      image.save(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", \"JPEG\", quality=70, exif=exif_bytes)\n",
        "    files = {f\"{image_folder:04}_{name:04}.{suffix}\": open(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", \"rb\").read()}\n",
        "    payload = {\"content\": f\"{prompt}\\nSteps: {num_inference_steps}, Sampler: {sampler}, CFG scale: {guidance_scale}, Seed: {real_seed}, Size: {width}x{height}, Model: {ckpt} - {discord_user}\"}\n",
        "    requests.post(f\"https://discord.com/api/v9/channels/{discord_channel_id}/messages\", data=payload, headers={\"authorization\": f\"Bot {discord_token}\"}, files=files)\n",
        "    os.remove(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ut2HKwJ7FlqR"
      },
      "outputs": [],
      "source": [
        "with open(\"template.json\", \"r\") as file:\n",
        "    prompts = file.readlines()\n",
        "for prompt in prompts:\n",
        "    d = json.loads(prompt)\n",
        "    name += 1\n",
        "    generate(d[\"discord_token\"], d[\"discord_channel_id\"], d[\"ckpt\"], \"camenduru\", d[\"by\"], d[\"num_inference_steps\"], d[\"guidance_scale\"], d[\"sampler\"], d[\"width\"], d[\"height\"], d[\"prompt\"], d[\"negative_prompt\"], d[\"suffix\"], image_folder, name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
