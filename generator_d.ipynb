{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/ai-creator-archive/blob/main/generator_d.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru4AP9GVFlqQ"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "\n",
        "# !apt -y update -qq\n",
        "# !wget http://launchpadlibrarian.net/367274644/libgoogle-perftools-dev_2.5-2.2ubuntu3_amd64.deb\n",
        "# !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/google-perftools_2.5-2.2ubuntu3_all.deb\n",
        "# !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libtcmalloc-minimal4_2.5-2.2ubuntu3_amd64.deb\n",
        "# !wget https://launchpad.net/ubuntu/+source/google-perftools/2.5-2.2ubuntu3/+build/14795286/+files/libgoogle-perftools4_2.5-2.2ubuntu3_amd64.deb\n",
        "# !apt install -qq libunwind8-dev\n",
        "# !dpkg -i *.deb\n",
        "# %env LD_PRELOAD=libtcmalloc.so\n",
        "# !rm *.deb\n",
        "\n",
        "!apt -y install -qq aria2 \n",
        "!pip install -q https://github.com/camenduru/stable-diffusion-webui-colab/releases/download/0.0.17/xformers-0.0.17+b6be33a.d20230315-cp39-cp39-linux_x86_64.whl\n",
        "!pip install -q triton==2.0.0\n",
        "!pip install diffusers==0.14.0 transformers accelerate==0.14.0 piexif fold_to_ascii discord ftfy omegaconf safetensors pytorch_lightning -U\n",
        "!wget -q https://raw.githubusercontent.com/huggingface/diffusers/v0.14.0/scripts/convert_original_stable_diffusion_to_diffusers.py -O convert_original_stable_diffusion_to_diffusers.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os, gc, requests, json, piexif, torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from PIL.PngImagePlugin import PngInfo\n",
        "from fold_to_ascii import fold\n",
        "from safetensors.torch import save_file, load_file\n",
        "\n",
        "metadata = PngInfo()\n",
        "\n",
        "def closestNumber(n, m):\n",
        "    q = int(n / m)\n",
        "    n1 = m * q\n",
        "    if (n * m) > 0:\n",
        "        n2 = m * (q + 1)\n",
        "    else:\n",
        "        n2 = m * (q - 1)\n",
        "    if abs(n - n1) < abs(n - n2):\n",
        "        return n1\n",
        "    return n2\n",
        "\n",
        "root_folder = 'images'\n",
        "\n",
        "if os.path.exists(f\"{root_folder}\") == False:\n",
        "    os.mkdir(f\"{root_folder}\")\n",
        "image_folder = max([int(f) for f in os.listdir(f\"{root_folder}\")], default=0)\n",
        "if os.path.exists(f\"{root_folder}/{image_folder:04}\") == False:\n",
        "    os.mkdir(f\"{root_folder}/{image_folder:04}\")\n",
        "name = max([int(f[: f.index(\".\")]) for f in os.listdir(f\"{root_folder}/{image_folder:04}\")], default=0)\n",
        "\n",
        "def load():\n",
        "    if 'pipe' in globals():  \n",
        "      pipe = None\n",
        "    with torch.no_grad():\n",
        "      torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\"/content/pt\", torch_dtype=torch.float16, safety_checker=None).to(\"cuda\")\n",
        "    pipe.enable_xformers_memory_efficient_attention()\n",
        "    return pipe\n",
        "\n",
        "def generate(pipe, seed, discord_token, discord_channel_id, ckpt, discord_user, by, num_inference_steps, guidance_scale, sampler, width, height, prompt, negative_prompt, suffix, image_folder, name):\n",
        "    print(ckpt)    \n",
        "    width = closestNumber(width, 8)\n",
        "    height = closestNumber(height, 8)\n",
        "    metadata.add_text(\"Prompt\", f\"{prompt}\")\n",
        "    metadata.add_text(\"by\", f\"{by}\")\n",
        "    gc.collect()\n",
        "    \n",
        "    generator = torch.cuda.manual_seed(seed)\n",
        "    real_seed = torch.cuda.initial_seed()\n",
        "    image = pipe(prompt=prompt, negative_prompt=negative_prompt, generator=generator, num_inference_steps=num_inference_steps, height=height, width=width, guidance_scale=guidance_scale).images[0]\n",
        "    if(suffix == 'png'):\n",
        "      image.save(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", pnginfo=metadata)\n",
        "    else:\n",
        "      zeroth_ifd = {piexif.ImageIFD.ImageDescription: f\"{fold(prompt)}\", piexif.ImageIFD.Make: f\"{fold(by)}\", piexif.ImageIFD.Model: f\"{ckpt}\", piexif.ImageIFD.Copyright: f\"Attribution 4.0 International (CC BY 4.0)\"}\n",
        "      exif_dict = {\"0th\": zeroth_ifd}\n",
        "      exif_bytes = piexif.dump(exif_dict)\n",
        "      image.save(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", \"JPEG\", quality=70, exif=exif_bytes)\n",
        "    files = {f\"{image_folder:04}_{name:04}.{suffix}\": open(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\", \"rb\").read()}\n",
        "    payload = {\"content\": f\"{prompt}\\nSteps: {num_inference_steps}, Sampler: {sampler}, CFG scale: {guidance_scale}, Seed: {real_seed}, Size: {width}x{height}, Model: {ckpt} - {discord_user}\"}\n",
        "    requests.post(f\"https://discord.com/api/v9/channels/{discord_channel_id}/messages\", data=payload, headers={\"authorization\": f\"Bot {discord_token}\"}, files=files)\n",
        "    os.remove(f\"{root_folder}/{image_folder:04}/{name:04}.{suffix}\")\n",
        "\n",
        "with open(\"template.json\", \"r\") as file:\n",
        "    prompts = file.readlines()\n",
        "for prompt in prompts:\n",
        "    d = json.loads(prompt)\n",
        "    name += 1\n",
        "    ckpt = d[\"ckpt\"]\n",
        "    model_suffix = ckpt.split(\"/\")[-1].split(\".\")[-1]\n",
        "    !rm -rf /content/pt /content/model\n",
        "\n",
        "    ckpt = f\"\\\"{ckpt}\\\"\"\n",
        "    !aria2c --console-log-level=error -c -x 16 -s 16 -k 1M {ckpt} -d /content -o model\n",
        "\n",
        "    if not model_suffix == \"safetensors\":\n",
        "      weights = torch.load(\"model\", map_location=\"cpu\")\n",
        "      if \"state_dict\" in weights:\n",
        "          weights = weights[\"state_dict\"]\n",
        "      save_file(weights, f\"model\")\n",
        "      weights = None\n",
        "\n",
        "    !python /content/convert_original_stable_diffusion_to_diffusers.py --from_safetensors --checkpoint_path /content/model --dump_path /content/pt\n",
        "    pipe = load()\n",
        "    for i in range(5):\n",
        "      seed = i + 69\n",
        "      generate(pipe, seed, d[\"discord_token\"], d[\"discord_channel_id\"], d[\"ckpt\"], \"camenduru\", d[\"by\"], d[\"num_inference_steps\"], d[\"guidance_scale\"], d[\"sampler\"], d[\"width\"], d[\"height\"], d[\"prompt\"], d[\"negative_prompt\"], d[\"suffix\"], image_folder, name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
